{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import tree\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "px.set_mapbox_access_token(config['MAPBOX_TOKEN'])\n",
    "pio.templates.default = \"plotly_white\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewFeatures:\n",
    "\n",
    "    # Adds the month number, e.g. second month of seconds year = (1 * 12) + 2 = 14\n",
    "    @staticmethod\n",
    "    def add_month_number(df):\n",
    "        '''\n",
    "        Returns a new DataFrame with addded column \"month_number\". The month_number starts at 1 and increments to the final month.\n",
    "        For instance, if the earliest date is January 2005, February 2005 = 2 and February 2006 = 14.\n",
    "        '''\n",
    "        df.YrSold = pd.to_numeric(df.YrSold)\n",
    "        df.MoSold = pd.to_numeric(df.MoSold)\n",
    "        base_year = df.YrSold.min()\n",
    "        df['month_number'] = (df.YrSold - base_year)*12 + df.MoSold\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Helpers:\n",
    "\n",
    "    # Returns two DataFrames, a training set with all months n-1, and a test set with just month n where the target var, SalePrice is stripped\n",
    "    @staticmethod\n",
    "    def separate_final_month(df):\n",
    "        '''\n",
    "        Returns two new DataFrames. The first DataFrame includes all records & columns except records from the final month (as determined by col month_number). \n",
    "        The second DataFrame includes all records & columns from the final month, except the target feature, SalePrice.\n",
    "        '''\n",
    "        if 'month_number' not in df:\n",
    "            df = df.NewFeatures.add_month_number(df)\n",
    "        \n",
    "        train_set = df.loc[df.month_number<df.month_number.max()]\n",
    "        test_set = df.loc[df.month_number==df.month_number.max()].drop(columns=['SalePrice'])\n",
    "\n",
    "        return train_set, test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pipeline**:\n",
    "\n",
    "1. Set Pipeline Options:\n",
    "- What Data Fixing Operations should be used (bool flags)\n",
    "- What new features (via methods) should be added\n",
    "- Scaling options to use (bool flags)\n",
    "- Model hyperparams\n",
    "\n",
    "2. Data Fixing\n",
    "- Remove inessential columns\n",
    "- Fix NA/missing values\n",
    "- Fix erroneous values (e.g. \"None\" vs None)\n",
    "- Remove outliers *with care*\n",
    "\n",
    "3. Feature Engineering\n",
    "- Add new features\n",
    "\n",
    "4. Feature Scaling\n",
    "- Convert categorical features\n",
    "- (optional) Scale/Normalize features\n",
    "- Standardize features\n",
    "\n",
    "5. Model preparation\n",
    "- split train/test (use k-folds)\n",
    "- set hyper-params (or use grid/random search)\n",
    "- set metrics and visual analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFixing:\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.df = None\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "    def fix(self, df):\n",
    "        # Loops through all class methods and calls the ones with prefix \"_\"\n",
    "        self.df = df\n",
    "        for attr_name in dir(self):\n",
    "            if attr_name[0] == '_' and attr_name[1] != '_':\n",
    "                attr = getattr(self, attr_name)\n",
    "                if callable(attr):\n",
    "                    print(f'before {attr_name}: {len(self.df)}')\n",
    "                    attr()\n",
    "                    print(f'after {attr_name}: {len(self.df)}')\n",
    "\n",
    "        return self.df\n",
    "\n",
    "    def _remove_columns(self, columns=None):\n",
    "        should_remove_columns = getattr(self, 'remove_columns', False)\n",
    "        if should_remove_columns:\n",
    "            columns = getattr(self, 'remove_columns_list', columns)\n",
    "            self.df = self.df.drop(columns=columns)\n",
    "\n",
    "    def _fix_na(self):\n",
    "        should_fix_na = getattr(self, 'fix_na', False)\n",
    "        if should_fix_na:\n",
    "            self.df = self.df.fillna(0)\n",
    "        pass\n",
    "\n",
    "    def _fix_error_values(self):\n",
    "        should_fix_error_values = getattr(self, 'fix_error_values', False)\n",
    "        if should_fix_error_values:\n",
    "            pass\n",
    "        pass\n",
    "\n",
    "    def _fix_outliers(self):\n",
    "        should_fix_outliers = getattr(self, 'fix_outliers', False)\n",
    "        if should_fix_outliers:\n",
    "            pass\n",
    "        pass\n",
    "\n",
    "    def _remove_non_numeric_columns(self):\n",
    "        should_remove_non_numeric = getattr(self, 'remove_non_numeric', False)\n",
    "        if should_remove_non_numeric:\n",
    "            self.df = self.df._get_numeric_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureGeneration:\n",
    "\n",
    "    def __init__(self, list_of_methods):\n",
    "        self.feature_methods = list_of_methods\n",
    "\n",
    "    def generate(self, df):\n",
    "        for method in self.feature_methods:\n",
    "            if callable(method):\n",
    "                df = method(df)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureScaler:\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.df = None\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "    def scale(self, df):\n",
    "        self.df = df\n",
    "        if len(self.df) == 0:\n",
    "            return False\n",
    "\n",
    "        if not self.columns_are_valid():\n",
    "            raise Exception(\"Ensure all columns are numeric\")\n",
    "        for attr_name in dir(self):\n",
    "            if attr_name[0] == '_' and attr_name[1] != '_':\n",
    "                attr = getattr(self, attr_name)\n",
    "                if callable(attr):\n",
    "                    attr()\n",
    "\n",
    "        return self.df\n",
    "\n",
    "    def columns_are_valid(self):\n",
    "        # ensure that all dtypes are numeric\n",
    "        dtypes = self.df.dtypes.unique()\n",
    "        if 'O' in dtypes:\n",
    "            print('found an o dtype')\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def _standardize_data(self):\n",
    "        should_standardize_features = getattr(self, 'standardize_data', False)\n",
    "        if should_standardize_features:\n",
    "            self.df = (self.df - self.df.mean()) / self.df.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modeler:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.clf = tree.DecisionTreeRegressor()\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.clf.fit(x, y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "\n",
    "    def calc_error(self, predicted, actual):\n",
    "        return np.sqrt((predicted - actual)**2)\n",
    "\n",
    "    def evaluate(self, df):\n",
    "        rmses = self.train(df, rounds=1)\n",
    "        return np.mean(rmses)\n",
    "\n",
    "    def train(self, df, rounds=1):\n",
    "        rmses = []\n",
    "        for _ in range(rounds):\n",
    "            # split into train, test datasets\n",
    "            x = df.drop(columns=['SalePrice'])\n",
    "            y_act = df.SalePrice\n",
    "\n",
    "            # fit\n",
    "            self.fit(x, y_act)\n",
    "\n",
    "            # TODO: of course this should be on a test set\n",
    "            y_pred = self.predict(x)\n",
    "\n",
    "            # Measure\n",
    "            rmse = self.calc_error(y_pred, y_act)\n",
    "            rmses.append(rmse)\n",
    "\n",
    "        return rmses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline:\n",
    "    def __init__(self, df, fixing_options, gen_options, scaling_options, modeling_options):\n",
    "        self.df = df\n",
    "        self.options = {'fix': fixing_options, 'gen': gen_options, 'scale': scaling_options, 'model': modeling_options}\n",
    "    \n",
    "    def validate(self):\n",
    "        return True\n",
    "    \n",
    "    def run(self):\n",
    "        fixer = DataFixing(**self.options['fix'])\n",
    "        feature_generator = FeatureGeneration(self.options['gen'])\n",
    "        scaler = FeatureScaler(**self.options['scale'])\n",
    "        modeler = Modeler()\n",
    "\n",
    "        self.df = fixer.fix(self.df)\n",
    "        self.df = feature_generator.generate(self.df)\n",
    "        self.df = scaler.scale(self.df)\n",
    "\n",
    "        score = modeler.evaluate(self.df)\n",
    "\n",
    "        print(f'Score: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fixing_options = {\n",
    "    'remove_columns': True,\n",
    "    'remove_columns_list': [\n",
    "        'Street',\n",
    "        'Alley',\n",
    "        'Utilities',\n",
    "        'Condition2',\n",
    "        'PoolQC',\n",
    "        'MiscFeature',\n",
    "        'RoofMatl',\n",
    "        'Heating',\n",
    "        'LowQualFinSF',\n",
    "        'PoolArea'\n",
    "    ],\n",
    "\n",
    "    'fix_na': True,\n",
    "    'fix_error_values': False,\n",
    "    'fix_outliers': False,\n",
    "    'remove_non_numeric': True\n",
    "}\n",
    "\n",
    "feature_engineering_methods = [\n",
    "    NewFeatures.add_month_number\n",
    "]\n",
    "\n",
    "data_scaling_options = {\n",
    "    'standardize_data':True, \n",
    "}\n",
    "\n",
    "modeling_options = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before _fix_error_values: 1460\n",
      "after _fix_error_values: 1460\n",
      "before _fix_na: 1460\n",
      "after _fix_na: 1460\n",
      "before _fix_outliers: 1460\n",
      "after _fix_outliers: 1460\n",
      "before _remove_columns: 1460\n",
      "after _remove_columns: 1460\n",
      "before _remove_non_numeric_columns: 1460\n",
      "after _remove_non_numeric_columns: 1460\n",
      "Score: 2.281280187585938e-19\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(df, data_fixing_options, feature_engineering_methods, data_scaling_options, modeling_options)\n",
    "pipe.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c481518f0c828bab2fc04cd2d881b7800b57b84f50190e329816569e316f7752"
  },
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit ('ai': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
